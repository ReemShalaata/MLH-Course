{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BME-336546-C06-Nonlinear classification (SVM and Random forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use(['ggplot']) \n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we would use data that you can find within `sklearn.datasets`. The chosen data are concentric circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_circles\n",
    "X, y = make_circles(1000, factor=.1, noise=.2, random_state=336546)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we should split our data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_radar(clf, clf_type):\n",
    "    labels=np.array(['Accuracy', 'F1', 'PPV', 'Sensitivity', 'AUROC']) \n",
    "    score_mat_train = np.stack((clf.cv_results_['mean_train_accuracy'], clf.cv_results_['mean_train_f1'],\n",
    "                               clf.cv_results_['mean_train_precision'], clf.cv_results_['mean_train_recall'],\n",
    "                               clf.cv_results_['mean_train_roc_auc']), axis=0)\n",
    "    score_mat_val = np.stack((clf.cv_results_['mean_test_accuracy'], clf.cv_results_['mean_test_f1'],\n",
    "                               clf.cv_results_['mean_test_precision'], clf.cv_results_['mean_test_recall'],\n",
    "                               clf.cv_results_['mean_test_roc_auc']), axis=0)\n",
    "\n",
    "\n",
    "    angles=np.linspace(0, 2*np.pi, len(labels), endpoint=False)\n",
    "\n",
    "    angles=np.concatenate((angles,[angles[0]]))\n",
    "    cv_dict = clf.cv_results_['params']\n",
    "    fig=plt.figure(figsize=(18,14))\n",
    "    if 'svm__gamma' in cv_dict[0]:\n",
    "        new_list = [(i, item) for i, item in enumerate(cv_dict) if\n",
    "                    item[\"svm__kernel\"] == clf_type[0] and item[\"svm__gamma\"] == clf_type[1]]\n",
    "    else:\n",
    "        new_list = [(i, item) for i, item in enumerate(cv_dict) if\n",
    "                    item[\"svm__kernel\"] == clf_type[0]]\n",
    "    for idx, val in enumerate(new_list):\n",
    "        ax = fig.add_subplot(1, len(new_list), 1+idx, polar=True)\n",
    "        rel_idx, rel_dict = val\n",
    "        stats_train = score_mat_train[:, rel_idx]\n",
    "        stats_train=np.concatenate((stats_train,[stats_train[0]]))\n",
    "        ax.plot(angles, stats_train, 'o-', linewidth=2)\n",
    "        ax.fill(angles, stats_train, alpha=0.25)\n",
    "        stats_val = score_mat_val[:, rel_idx]\n",
    "        stats_val=np.concatenate((stats_val,[stats_val[0]]))\n",
    "        ax.plot(angles, stats_val, 'o-', linewidth=2)\n",
    "        ax.fill(angles, stats_val, alpha=0.25)\n",
    "        ax.set_thetagrids(angles[:-1] * 180/np.pi, labels)\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(clf_type[0], fontsize=18)\n",
    "        ax.set_title('C = %.3f' % (rel_dict['svm__C']))\n",
    "        if 'svm__gamma' in cv_dict[0]:\n",
    "            ax.set_xlabel('$\\gamma = %s $' % (rel_dict['svm__gamma']))\n",
    "        ax.set_ylim([0,1])\n",
    "        ax.legend(['Train','Validation'])\n",
    "        ax.grid(True)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def plot_dataset(x_train, x_test, y_train, y_test, axes_range):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        if idx == 0:\n",
    "            ax.plot(x_train[:, 0][y_train==0], x_train[:, 1][y_train==0], \"bs\")\n",
    "            ax.plot(x_train[:, 0][y_train==1], x_train[:, 1][y_train==1], \"g^\")\n",
    "            ax.set_title('Train')\n",
    "        else:\n",
    "            ax.plot(x_test[:, 0][y_test==0], x_test[:, 1][y_test==0], \"bs\")\n",
    "            ax.plot(x_test[:, 0][y_test==1], x_test[:, 1][y_test==1], \"g^\")\n",
    "            ax.set_title('Test')\n",
    "        ax.axis(axes_range)\n",
    "        ax.grid(True, which='both')\n",
    "        ax.set_xlabel(r\"$x_1$\", fontsize=20)\n",
    "        ax.set_ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(clf, axs, axes_range):\n",
    "    x0s = np.linspace(axes_range[0], axes_range[1], 100)\n",
    "    x1s = np.linspace(axes_range[2], axes_range[3], 100)\n",
    "    x0, x1 = np.meshgrid(x0s, x1s)\n",
    "    X = np.c_[x0.ravel(), x1.ravel()]\n",
    "    y_pred = clf.predict(X).reshape(x0.shape)\n",
    "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
    "    for idx, ax in enumerate(axs.flatten()):\n",
    "        ax.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
    "        ax.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
    "        if idx == 0:\n",
    "            ax.set_title('Train')\n",
    "        else:\n",
    "            ax.set_title('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_range = [-3, 3, -2, 2]\n",
    "_, _ = plot_dataset(X_train, x_test, Y_train, y_test, axes_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is clearly non-linearly separable, at least not at this domain. We should now use the `StratifiedKFold` class as in the previous tutorial with 3 splits and then we will use `GridSearchCV` to look for the best linear SVM among the different given C values for classification penalties. Use `Pipeline` to insert scaling and notice that the kernel should not be a string but rather a one-element list containing the adequate string for linear kernel.\\\n",
    "Again, we would look for the best estimator according to AUROC performance and for \"running info\" we would use `verbose=3`. Name the `GridSearchCV` as `svm_lin` and use `svm` string for the dictionary of `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#C1\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = SVC(probability=True, random_state=336546)\n",
    "C = np.array([0.001, 0.01, 1, 10, 100, 1000])\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best linear model and name it as `best_svm_lin`. In addition, print the parameters adequate to the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C2\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/1.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the performances as a function of missclassification penalties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_type = ['linear']\n",
    "plot_radar(svm_lin, clf_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/2.PNG\" width=\"880\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we would like to visualize the classification of our chosen estimator using `decision_function` method (used within `plot_predictions`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes_range = [-3, 3, -2, 2]\n",
    "_, axs = plot_dataset(X_train, x_test, Y_train, y_test, axes_range)\n",
    "plot_predictions(best_svm_lin, axs, axes_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/3.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "calc_TN = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 0]\n",
    "calc_FP = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[0, 1]\n",
    "calc_FN = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[1, 0]\n",
    "calc_TP = lambda y_true, y_pred: confusion_matrix(y_true, y_pred)[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the statistics and plot the confusion matrix as in previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#C3\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score\n",
    "\n",
    "y_pred_test = best_svm_lin.predict(x_test) #NOTICE NOT TO USE THE STANDARDIZED DATA.\n",
    "y_pred_proba_test = best_svm_lin.predict_proba(x_test)\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('AUROC is {:.3f}'.format(roc_auc_score(y_test, y_pred_proba_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/4.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would look for a **nonlinear** SVM calssifier. Use the kernels `rbf` and `poly`. For $\\gamma$, use `auto` and `scale`. The order of the polynom should be 3 (so it won't take more than several minutes). Notice to use a single-element list for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#C4\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = SVC(probability=True)\n",
    "C = np.array([1, 100, 1000])#, 10, 100, 1000])\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best estimator and name it as `best_svm_nonlin`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:red\">***Question:***</span> *Which kernel do you think is more proper to use?*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C5\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/5.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can plot The performances as a function of missclassification penalties for different kernels and $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "clf_type = ['rbf', 'scale']\n",
    "plot_radar(svm_nonlin, clf_type)\n",
    "clf_type = ['poly', 'scale']\n",
    "plot_radar(svm_nonlin, clf_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/6.PNG\" width=\"700\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the decision function upon our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plot_dataset(X_train, x_test, Y_train, y_test, axes_range)\n",
    "plot_predictions(best_svm_nonlin, axs, axes_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/7.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the statistics and plot the confusion matrix as in previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#C6\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score\n",
    "\n",
    "y_pred_test = best_svm_nonlin.predict(x_test) #NOTICE NOT TO USE THE STANDARDIZED DATA.\n",
    "y_pred_proba_test = best_svm_nonlin.predict_proba(x_test)\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('AUROC is {:.3f}'.format(roc_auc_score(y_test, y_pred_proba_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/8.PNG\" width=\"400\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will only introduce a powerful classifier named *random forest* that was also used in the last part of *HW1*. Calculate the statistics and plot the confusion matrix as in previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#C7\n",
    "from sklearn.metrics import plot_confusion_matrix, roc_auc_score,plot_roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = Pipeline(steps=[('scale', StandardScaler()), ('rfc', RandomForestClassifier(max_depth=4, random_state=336546, criterion='gini'))])\n",
    "rfc.fit(X_train, Y_train)\n",
    "y_pred_test = rfc.predict(x_test) #NOTICE NOT TO USE THE STANDARDIZED DATA.\n",
    "y_pred_proba_test = rfc.predict_proba(x_test)\n",
    "#--------------------------Impelment your code here:-------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "print('AUROC is {:.3f}'.format(roc_auc_score(y_test, y_pred_proba_test[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/9.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will compare the classifiers according to AUROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [best_svm_lin, best_svm_nonlin, rfc]\n",
    "roc_score = []\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "for clf in classifiers:\n",
    "    plot_roc_curve(clf, x_test, y_test, ax=ax)\n",
    "    roc_score.append(np.round_(roc_auc_score(y_test, clf.predict_proba(x_test)[:,1]), decimals=3))\n",
    "ax.plot(np.linspace(0,1,x_test.shape[0]),np.linspace(0,1,x_test.shape[0]))\n",
    "plt.legend(('lin_svm, AUROC = '+str(roc_score[0]),'nonlin_svm, AUROC = '+str(roc_score[1]),'rfc, AUROC = '+str(roc_score[2]),'flipping a coin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected outpout:\n",
    "<center><img src=\"outputs/10.PNG\" width=\"380\"><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *This tutorial was written by [Moran Davoodi](mailto:morandavoodi@gmail.com) & Alon Begin with the assitance of [Yuval Ben Sason](mailto:yuvalbse@gmail.com) & Kevin Kotzen*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
